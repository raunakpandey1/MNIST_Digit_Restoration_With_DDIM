# DDIM Inpainting on MNIST (Center-Hole)

Train a **timestep-conditioned U-Net** diffusion model on **masked MNIST** and reconstruct the missing center region using **DDIM sampling**. Evaluation is reported **only inside the hole** using **hole-only PSNR** and **hole-only L1 (MAE)**.

**Notebook:** `DDIM_Inpainting_Student.ipynb`

---

## Project Overview
This project implements an end-to-end diffusion inpainting pipeline:
1. **Mask MNIST** with a fixed **center box hole** (known pixels kept, hole removed).
2. Train a diffusion model (U-Net) with **timestep conditioning** to learn the reverse process.
3. Run **DDIM inpainting** with a **data-consistency step** that preserves known pixels at every reverse step.
4. Measure reconstruction quality **only inside the hole**.

---

## Key Features
- **Center-hole inpainting** on MNIST (resized to **32×32**, normalized to **[-1, 1]**).
- **Timestep-conditioned U-Net** with sinusoidal time embeddings.
- **Cosine / linear beta schedule** (default: cosine).
- **DDIM sampling** (fast; deterministic when `eta=0`).
- **Data consistency** repeated `dc_repeats` times per reverse step for cleaner seams.
- Optional training/sampling improvements:
  - **EMA** (Exponential Moving Average) weights for better sampling
  - **Self-conditioning**
  - **Coord-Conv** (adds `(x,y)` coordinate channels)
  - **P2 reweighting** (SNR-balanced timestep loss)
  - **Hole-weighted loss** (emphasize the missing region)
- **Hole-only metrics**:
  - `psnr_on_mask(pred, target, known_mask)`
  - `l1_on_mask(pred, target, known_mask)`

---

## Methodology

### 1) Masked Inpainting Setup
- A **known-mask** `m` is created with:
  - `m = 1` for known pixels
  - `m = 0` inside the center hole
- The observed input is:
  - `y = m * x0`

### 2) Forward Diffusion (Noising)
Forward noising at timestep `t`:

\[
x_t = \sqrt{\bar\alpha_t} x_0 + \sqrt{1-\bar\alpha_t}\,\epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
\]

### 3) Model (U-Net + Time Conditioning)
The network is conditioned on timestep `t` using a **sinusoidal embedding** + MLP. The base conditioning channels are:

- **Base:** `[x_t, m, y]` → **3 channels**
- **+ self-conditioning:** add `x0_sc` → **+1 channel**
- **+ coord-conv:** add `(coord_x, coord_y)` → **+2 channels**

### 4) DDIM Inpainting + Data Consistency
DDIM updates the reverse step using predicted \(\hat x_0\) and \(\hat\epsilon\). After proposing the next state, we enforce **known pixels** to stay consistent with the observation (at the matching noise level), repeated `dc_repeats` times.

---

## Repository Contents
- `DDIM_Inpainting_Student.ipynb` — everything (data, model, training, sampling, evaluation)
- Outputs generated by the notebook:
  - `outputs/inpaint/last.pt` — checkpoint (model + EMA + config)
  - `outputs/inpaint/panel_*.png` — training panels (GT / masked / reconstruction)
  - `outputs/inpaint/panel_final.png` — final panel after training
  - `outputs/inpaint/samples.png` — sample panel after `sample_cmd`
  - `results/inpaint_metrics.json` — evaluation metrics from `eval_cmd`

---
 
 

 